

# Jafar Abdollahi

<h2> Discription </h2>
# tracking-Mouse-
The ability to track animals accurately is critical for behavioral experiments. For video-based assays, this is often accomplished by manipulating environmental conditions to increase contrast between the animal and the background in order to achieve proper foreground/background detection (segmentation). Modifying environmental conditions for experimental scalability opposes ethological relevance. The biobehavioral research community needs methods to monitor behaviors over long periods of time, under dynamic environmental conditions, and in animals that are genetically and behaviorally heterogeneous. To address this need, we applied a state-of-the-art neural network-based tracker for single mice. We compare three different neural network architectures across visually diverse mice and different environmental conditions. We find that an encoder-decoder segmentation neural network achieves high accuracy and speed with minimal training data. Furthermore, we provide a labeling interface, labeled training data, tuned hyperparameters, and a pretrained network for the behavior and neuroscience communities.



<h2> Dataset </h2>
Neural network training sets used in this study are available on the kumarlab website https://www.kumarlab.org/2019/02/12/single-mouse-tracking-annotated-dataset/. Pretrained neural networks used in this study are available on the kumarlab website https://www.kumarlab.org/2019/02/12/pre-trained-single-mouse-tracking-neural-network-models/. Strain survey distance traveled data used in this study are available in MPD.



<h2> Conlusion </h2>
We first used existing tracking methods to track 58 different mouse strains in multiple environments, and found them inadequate for our large-scale strain survey experiment (1845 videos, 1691â€‰h). We tracked all the videos in this experiment using both Ctrax28, a modern open-source tracking software package that uses background subtraction and blob detection heuristics, and LimeLight (Actimetrics, Wilmette, IL), a commercially available tracking software package that uses a proprietary tracking algorithm. Ctrax uses a background subtraction algorithm to abstract a mouse on a per frame basis to five metrics: major and minor axis, x and y location of center of the mouse, and the direction of the animal28. LimeLight uses a single key-frame background model for segmentation and detection, abstracting the mouse to a center of mass using a proprietary algorithm
<img src="https://github.com/Jafar-Abdollahi/tracking-Mouse-/blob/main/2021-06-28_22-05-03.jpg"> 
<img src="https://github.com/Jafar-Abdollahi/tracking-Mouse-/blob/main/2021-06-28_22-06-24.jpg"> 
<img src="https://github.com/Jafar-Abdollahi/tracking-Mouse-/blob/main/2021-06-28_22-07-08.jpg"> 
<img src="https://github.com/Jafar-Abdollahi/tracking-Mouse-/blob/main/2021-06-28_22-07-38.jpg"> 


<h2> Paper </h2>

<h2> Contact me </h2>
You can reach me at:

Email: ja.abdollahi77@gmail.com
<br>
LinkedIn: https://www.linkedin.com/in/jafar-abdollahi-7647971b3/
<br>
Google Scholar: https://scholar.google.com/citations?user=2dK8kPwAAAAJ&hl=en
<br>
researchgate: https://www.researchgate.net/profile/Jafar-Abdollahi?ev=hdr_xprf&_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6ImxvZ2luIiwicGFnZSI6ImhvbWUiLCJwcmV2aW91c1BhZ2UiOiJsb2dpbiIsInBvc2l0aW9uIjoiZ2xvYmFsSGVhZGVyIn19
<br>
youtube: https://www.youtube.com/@jafarabdollahi/featured
<br>
<img src="https://github.com/Jafar-Abdollahi/cuffless-bp-master-in-python-jupyter-/blob/main/2024-07-07_19-45-22.png"> 
